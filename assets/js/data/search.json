[ { "title": "Vue3 渲染函数与代理对象踩坑记录", "url": "/blog/posts/Vue3-%E6%B8%B2%E6%9F%93%E5%87%BD%E6%95%B0%E4%B8%8E%E4%BB%A3%E7%90%86%E5%AF%B9%E8%B1%A1%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/", "categories": "Vue, 前端", "tags": "Vue, 前端, 踩坑记录", "date": "2021-11-23 17:00:00 +0800", "snippet": " 本文的示例基于 TypeScript 和 vue-class-component假设有一个第三方组件的 option 属性，它包含了一个渲染函数：export default class Foo extends Vue { @Prop(Number) private prop: number = 0 private option = { render: (arg: any) =&amp;gt; h(&quot;button&quot;, { onClick: () =&amp;gt; this.click(arg) // 这里的 this 是原始的 Foo 对象 }, {default: () =&amp;gt; &quot;点我&quot;}) } click(arg: any) { console.debug(arg) console.debug(this.prop) // 总是输出默认值 0 }}以上代码，在点击 点我 按钮时，控制台将输出 0，无论父组件给 Foo 组件的 prop 绑定了什么值。原因和解决方案Vue 3 中的实例是一个封装的代理对象，有时候我们使用一些第三方组件需要绑定一些带渲染函数的对象，这时候 this 指向的是原始对象，无法响应 Vue 示例中的数据变化。可以使用以下写法：let self: anyexport default class Foo extends Vue { @Prop(Number) private prop: number = 0 private option = { render: (arg: any) =&amp;gt; h(&quot;button&quot;, { onClick: () =&amp;gt; self.click(arg) // self 是 Foo 的代理对象 }, {default: () =&amp;gt; &quot;点我&quot;}) } beforeMount() { // 这里的 this 是代理对象，赋值给 self 全局变量 self = this } click(arg: any) { console.debug(this.prop) }}在 beforeMount 方法中，this 是代理对象，将它赋值给全局变量 self，然后通过 self 来绑定事件。" }, { "title": "CMake 快速入门", "url": "/blog/posts/CMake-%E5%85%A5%E9%97%A8/", "categories": "CMake, C", "tags": "CMake, C", "date": "2021-10-11 13:00:00 +0800", "snippet": "单源文件配置假设有 main.c 文件：#include &amp;lt;stdio.h&amp;gt;int main(){ printf(&quot;Hello, World!&quot;); return 0;}CMakeList.txt 内容：# 设置 CMake 最低版本要求cmake_minimum_required(VERSION 3.0)# 项目名称project(HelloWorld)set(CMAKE_C_STANDARD 11) # 指定 C 标准# 指定生成可执行文件add_executable(HelloWorld main.c)以上内容就是最简单的单文件项目的配置了。多源文件/多目录配置假设我们需要把头文件和源文件分开存放，并且有多个生成目标：.├── CMakeList.txt├── include│   ├── bar.h│   └── foo.h└── src ├── bar.c ├── foo.c └── main.c假设有以上目录结构，仅生成一个目标：project(foobar)set(CMAKE_C_STANDARD 11)# 指定头文件目录，可以设置多个，空格/换行隔开include_directories( include)# 指定源文件目录，第一个参数为目录，第二个为变量，可以在此文件中引用aux_source_directory(src SOURCE_DIR)# 将 src 目录中的源文件编译为 foobar 可执行文件add_executable(foobar ${SOURCE_DIR})如果要生成多个目标：add_executable(foo src/foo.c)add_executable(bar src/bar.c)如果每个目标都有多个文件，可以将不同目标的文件按目录分类：aux_source_directory(src/foo SRC_FOO)aux_source_directory(src/bar SRC_BAR)add_executable(foo ${SRC_BAR})add_executable(bar ${SRC_BAR}) AUX_SOURCE_DIRECTORY 的作用是发现指定目录中的源代码文件并将列表存储在一个变量中。生成 CMake 构建文件在 CMakeList.txt 所在目录执行以下命令：mkdir cmake-build-debug \\&amp;amp;&amp;amp; cd ./cmake-build-debug \\&amp;amp;&amp;amp; cmake -DCMAKE_BUILD_TYPE=Debug -G &#39;CodeBlocks - Unix Makefiles&#39; ..以上命令的作用： 创建一个目录用来存放构建文件 切换到构建目录，运行 cmake 程序生成文件 注意：不要在项目根目录运行 cmake 命令来生成文件，否则生成的各种构建文件会直接与项目文件混在一起！参数说明： -DCMAKE_BUILD_TYPE 构建类型，可选 Debug 和 Release -G 生成器名称，默认是 Unix Makefiles在构建目录运行 make 即可生成目标。" }, { "title": "Steam for Linux 设置代理", "url": "/blog/posts/Steam-for-Linux-%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86/", "categories": "Linux, Steam", "tags": "Linux, Steam", "date": "2020-09-30 16:00:00 +0800", "snippet": "用正确的姿势给 Steam for Linux 设置代理为什么会有此文档？在使用 Linux Mint 时，发现 Steam 客户端打不开社区，但是 Chrome 可以打开，于是去找 Steam 客服，得到的回复是让我使用 Ubuntu，行吧，反正我正好有换 Ubuntu 的打算（Mint 的字体渲染不清晰）。然而，Ubuntu 的 Steam 客户端依然打不开社区，客服说让去 GitHub 讨论，然后我分析了一下，破案了： 国内是无法访问 Steam 社区的，需要挂梯子（我确实挂了） Steam for Windows 默认使用 IE 的代理，因此，挂梯子有效 Steam for Linux 不能使用代理，也无法通过客户端设置解决方案（1）既然 Steam 不能设置代理，那就用第三方的工具让它走代理咯～1. 安装 proxychainssudo apt-get install proxychains编辑 proxychains 的配置文件（在 /etc/proxychains.conf），以下是示例：socks5 127.0.0.1 7891http 127.0.0.1 7890我用的是 Clash，所以端口是 7890 和 7891，根据自己使用的代理软件来设置即可。2. 修改 Steam 的桌面入口文件文件的位置是：/usr/share/applications/steam.desktop找到 Exec 部分，改为：Exec=/usr/bin/proxychains /usr/games/steam %U现在点击 Steam 图标启动就可以愉快地打开所有页面了。 注意：此方法会导致部分游戏打不开，建议单独使用浏览器去使用社区和创意工坊！解决方案（2） 把代理挂载路由器上，选择支持华硕固件、老毛子固件的路由器，有钱直接上 AC86U 虚拟机跑软路由挂代理 Windows 它不香吗？" }, { "title": "Docker 实战—使用 Dockerfile 构建镜像", "url": "/blog/posts/Docker%E5%AE%9E%E6%88%98-%E4%BD%BF%E7%94%A8-Dockerfile-%E6%9E%84%E5%BB%BA%E9%95%9C%E5%83%8F/", "categories": "Docker", "tags": "Docker", "date": "2019-11-03 17:00:00 +0800", "snippet": "使用 Alpine Linux 作为基础镜像Alpine 是一个非常轻量的 Linux 镜像，他只有大约 5MB 的大小，基于它构建镜像，可以大大减少镜像的体积。docker pull alpineAlpine 使用 apk 命令来安装软件包，支持的软件包列表可以在官网查看：https://pkgs.alpinelinux.org/packages这里以安装 Nginx 为例，学习镜像的构建。另外 Nginx 本身有官方镜像，pull 即可。构建 Nginx 镜像编写 DockerfileFROM alpineRUN apk update \\ # 安装 nginx apk add --no-cache nginx \\ mkdir /run/nginx &amp;amp;&amp;amp; \\ # 清除缓存 rm -rf /tmp/* /var/cache/apk/* # 添加容器启动命令，启动 nginx，以前台方式运行CMD [ &quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot; ]这里有一个坑点，必须创建 /run/nginx 目录，不然会报错。构建镜像使用 docker build 命令构建：docker build -t nginx-alpine .在 Dockerfile 目录下执行以上命令即可构建镜像。-t 参数指定了镜像名称为 nginx-alpine，最后的 . 表示构建上下文（. 表示当前目录）.在使用 COPY 指令复制文件时，指令中的源路径是相对于构建上下文的（如果指定上下文为 /home，那么相当于所有的源路径前面都加上了 /home/）。如果你的 Dockerfile 文件名不是 “Dockerfile”，可以使用 -f 参数指定。 千万不要将 Dockerfile 放在根目录下构建，假如你将 Dockerfile 放在一个存放大量视频目录下，并且构建上下文为当前目录，那么镜像将会非常大（视频都被打包进去了）。最佳做法是将 Dockerfile 和需要用到的文件放在一个单独的目录下。运行容器使用构建的镜像运行容器：docker run --name my-nginx -p 80:80 -d nginx-apline --name 指定容器的名称，可以省略（后续只能通过容器 id 来操作）； -p 映射端口，宿主端口 -&amp;gt; 容器端口； -d 后台运行。运行后访问 http://localhost/，会出现一个 nginx 的 404 页面，说明已经运行成功了，因为这里安装的 Nginx 并没有默认页面，/etc/nginx/conf.d/default.conf 中的内容：server { listen 80 default_server; listen [::]:80 default_server; # Everything is a 404 location / { return 404; }}使用构建的 Nginx 镜像运行一个静态页面在一个空目录下创建 Nginx 配置文件：server { listen 80 default_server; listen [::]:80 default_server; root /var/www; location / { index index.html; }}编写一个静态页面：&amp;lt;!DOCTYPE html&amp;gt;&amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;title&amp;gt;Index&amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;h1&amp;gt;Hello, Docker!&amp;lt;/h1&amp;gt; &amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;使用之前构建的镜像构建一个新的镜像：FROM nginx-alpine# 拷贝配置文件，覆盖默认的COPY default.conf /etc/nginx/conf.d/# 拷贝静态页面COPY index.html /var/www构建镜像、运行容器：docker build -t site .docker run --name my-site -p 80:80 -d site现在访问 http://localhost/，就可以看到 Hello, Docker!" }, { "title": "Dockerfile 指令详解", "url": "/blog/posts/Dockerfile-%E6%8C%87%E4%BB%A4%E8%AF%A6%E8%A7%A3/", "categories": "Docker", "tags": "Docker", "date": "2019-10-24 21:00:00 +0800", "snippet": "FROMFROM 命令指定基础镜像。在构建镜像时，基础镜像必须指定，因此在 Dockerfile 中 FROM 是必备指令且必须是第一条指令。在 Docker Hub 上有很多常用的高质量官方镜像，有一些是应用和服务类的镜像，如 nginx、mysql、redis 等；也有一些是用于运行各种语言应用的镜像，如 openjdk、python、node 等。如果找不到应用的官方镜像，可以基于操作系统镜像构建一个。Docker Hub 上提供了很多操作系统镜像。FROM ubuntu...RUNRUN 指令是用来执行命令行命令的。RUN 指令的格式有两种： shell 格式：RUN &amp;lt;命令&amp;gt;，就像直接在命令行中输入命令一样。 RUN java -jar app.jar exec 格式：RUN [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;]。 RUN [&quot;java&quot;, &quot;-jar&quot;, &quot;app.jar&quot;] 在 Dockerfile 中，每一个指令都会在镜像上建立一层，所以对于多个命令行，不要写多个 RUN 指令。对于多个命令，可以使用这样的写法：FROM ubuntuRUN apt-get update \\ &amp;amp;&amp;amp; apt-get install -y redis对于多个命令，使用 &amp;amp;&amp;amp; 连接起来，只用一个 RUN 指令执行，这样就只会构建一层。COPYCOPY 指令用来将宿主的文件目录复制到镜像中。有两种格式： COPY [--chown=&amp;lt;user&amp;gt;:&amp;lt;group&amp;gt;] &amp;lt;源路径&amp;gt;... &amp;lt;目标路径&amp;gt; COPY app.jar /usr/src/ COPY [--chown=&amp;lt;user&amp;gt;:&amp;lt;group&amp;gt;] [&quot;源路径1&quot;, ... &quot;目标路径&quot;] COPY [&quot;app.jar&quot;, &quot;config.yml&quot;, &quot;/usr/src&quot;] 对于多个路径参数，最后一个为目标路径，其他都是源路径。目标路径 可以是绝对路径，也可以是相对于工作目录的路径（工作目录可以用 WORKDIR 来指定）。目标路径如果不存在，在复制文件前会先创建。CMDCMD 是容器启动命令，它指定了容器启动后要执行的程序。与 RUN 指令相似有两种形式： shell 格式：CMD &amp;lt;命令&amp;gt; CMD echo &#39;Hello, world!&#39;&#39; exec 格式：CMD [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;, ...] CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo &#39;Hello, world!&#39;&quot; ] 还有一种参数列表格式：CMD [&quot;参数1&quot;, &quot;参数2&quot;, ...]。在指定了 ENTRYPOINT 指令后，可以用 CMD 指定参数。在使用 CMD 时，程序必须以前台运行，Docker 不是虚拟机，容器没有后台服务的概率。如果使用 CMD 运行一个后台程序，那么容器在命令执行完就会退出。CMD java -jar app.jar &amp;amp;以上命令让 app.jar 在后台运行，容器启动后就会立刻退出。Docker 容器与守护线程很相似，当所有前台程序退出后，容器就会退出。CMD 指定的命令可以在运行时替换，跟在镜像名称后面的参数将替换镜像中的 CMD。docker run app echo $HOME以上命令运行容器时使用 echo $HOME 替换掉镜像中的启动命令。ENTRYPOINTENTRYPOINT 的格式与 CMD 一样有两种格式。它和 CMD 一样都是指定容器启动的程序和参数，但稍有区别。当指定了 ENTRYPOINT 后，CMD 的内容将作为参数加到 ENTRYPOINT 后面。也就是变成了：&amp;lt;ENTRYPOINT&amp;gt; &quot;&amp;lt;CMD&amp;gt;&quot;ENTRYPOINT 可以让镜像像命令一样使用，当仅仅使用 CMD 时，run 命令中镜像名后面的参数会替换 CMD 的内容。使用 ENTRYPOINT 后，这些参数将附加到原来命令的后面。FROM alpineENTRYPOINT [ &quot;ls&quot; ]使用以上 Dockerfile 构建的镜像运行容器：docker run app -al-al 参数将附加到 ENTRYPOINT 指定的命令后面，当容器启动时执行的是 ls -al。ENVENV 指令用来设置环境变量，格式有两种： ENV &amp;lt;key&amp;gt; &amp;lt;value ENV &amp;lt;key1&amp;gt;=&amp;lt;value1&amp;gt; &amp;lt;key2&amp;gt;=&amp;lt;value2&amp;gt;环境变量在后面的其它指令中可以通过 $key 来使用：FROM ubuntuENV VERSION=&quot;8-jre&quot;RUN apt-get update \\ &amp;amp;&amp;amp; apt-get install -y openjdk-$VERSION...ARGARG 指令指定构建参数，与 ENV 效果一样，都是设置环境变量。不同的是，ARG 设置的构建参数，在容器运行时不存在。格式：ARG &amp;lt;key&amp;gt;[=&amp;lt;默认值&amp;gt;]，可以指定默认值，也可以不指定。FROM alpineARG NAME=&quot;Hello, Docker!&quot;RUN echo $NAMECMD echo $NAME对于以上 Dockerfile，在构建时可以看到输出，但是在运行容器时没有输出。ARG 设置的参数可以在构建命令中指定：docker build --build-arg &amp;lt;key&amp;gt;=&amp;lt;value&amp;gt;。VOLUMEVOLUME 指令用来定义匿名卷。 VOLUME &amp;lt;路径&amp;gt; VOLUME [&quot;路径1&quot;, &quot;路径2&quot;, ...]对于数据库类需要保持数据的应用，其文件应该保存于卷（volume）中，在 Dockerfile 中，可以事先将指定的目录挂载为匿名卷。VOLUME /data这里 /data 目录在容器运行时自动挂载为匿名卷，任何写入 /data 中的数据都不会记录到容器的存储层。在运行时可以覆盖这个挂载设置：docker run -v dbdir:/data以上命令将 dbdir 目录挂载到了 /data，替换了 Dockerfile 中的挂载配置。EXPOSEEXPOSE 指令指定容器运行时暴露的端口。格式：EXPOSE &amp;lt;端口1&amp;gt; [&amp;lt;端口2&amp;gt; ...]。FROM ubuntuEXPOSE 8080RUN apt-get update \\ &amp;amp;&amp;amp; apt-get install -y tomcat8...以上 Dockerfile 安装了 tomcat 应用，在运行容器时会暴露 8080 端口。EXPOSE 只是指定了容器暴露的端口，并不会在宿主机进行端口映射。在使用 docker run -P 时，会自动随机映射 EXPOSE 指定的端口，也可以使用 -p 指定端口：docker run -p &amp;lt;宿主端口&amp;gt;:&amp;lt;容器端口&amp;gt;。WORKDIRWORKDIR 指令指定工作目录，即指定当前目录，类似于 cd 命令，以后各层的当前目录都是 WORKDIR 指定的目录。如果目录不存在，会自动创建。格式：WORKDIR &amp;lt;目录路径&amp;gt;。不能把 Dockerfile 当成 Shell 脚本来写：RUN cd /src/appRUN java -jar app.jar以上操作中第二行的工作目录并不是 /src/app，两个指令不在同一层，第一个 RUN 指令的 cd 操作和第二个没有任何关系。因此要切换目录，应该使用 WORKDIR 来指定。USERUSER 指令指定当前用户。与 WORKDIR 相似，会影响以后的层。USER 改变执行 RUN、CMD 和 ENTRYPOINT 的用户。格式：USER &amp;lt;用户名&amp;gt;[:&amp;lt;用户组&amp;gt;]。USER 指定的用户和组必须是事先创建好的，否则无法切换。# 添加用户RUN groupadd -r redis \\ &amp;amp;&amp;amp; useradd -r -g redis redisUSER redisENTRYPOINT [&quot;reids-server&quot;]ONBUILDONBUILD 指令后面跟的是其它指令，它在当前镜像构建时不会被执行，只有以当前镜像为基础镜像去构建下一级镜像时才会被执行。格式：ONBUILD &amp;lt;其它指令&amp;gt;。FROM openjdk:8-jre-alpineWORKDIR /appONBUILD COPY ./app.jar /app...这个 Dockerfile 在构建时不会执行 ONBUILD。FROM my-jre...假设之前构建的镜像名是 my-jre，以上 Dockerfile 构建镜像时，原来的 ONBUILD 将执行。" }, { "title": "Java 函数式编程--流操作", "url": "/blog/posts/Java-%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B-%E6%B5%81%E6%93%8D%E4%BD%9C/", "categories": "Java", "tags": "Java, 函数式编程", "date": "2019-10-23 20:00:00 +0800", "snippet": "外部迭代到内部迭代在使用集合类时，通用的方式是在使用 for 循环集合上进行迭代，然后处理每一个元素。比如计算集合中来自上海的用户：int count = 0;for (User user : allUsers) { if (user.isFrom(&quot;Shanghai&quot;)) { count++; }}以上代码为外部迭代，这样的方式要写很多样板代码。另一种方式是内部迭代：long count = allUsers.stream() .filter(user -&amp;gt; user.isFrom(&quot;Shanghai&quot;)) .count();整个过程变成了函数调用，且被分解为两个简单的操作： 找出所有来自上海的用户。 计算他们的数量。每种操作都对应 Stream 接口的一个方法。为了找出来自上海的用户，需要对 Stream 对象进行过滤：filter() 方法，该方法接受一个 lambda 表达式，最后由 count() 方法计算给定的 Stream 中包含多少对象。只调用 filter() 方法并不会做任何操作：allUsers.stream() .filter(user -&amp;gt; { out.println(user.name); return user.isFrom(&quot;Shanghai&quot;) });以上代码不会产生任何输出，只有最后调用了 count() 方法，才能看到输出。filter 方法返回的是一个 Stream 对象，这个过程和建造者模式相似。建造者模式通过一系列的操作设置属性，只有最后调用了 build() 方法对象才会被创建。在这里 filter() 方法只是传递了一个 lambda 表达式，只有在 count() 方法被调用时才会去执行它。常用的流操作filterfilter() 方法在上一部分已经出现过，它使用给定的 lambda 表达式检查流中的元素，并过滤出符合条件的元素。List&amp;lt;User&amp;gt; usersFromShanghai = allUsers.stream() // 过滤出来自上海的用户 .filter(user -&amp;gt; user.isFrom(&quot;Shanghai&quot;)) .collect(Collectors.toList());filter() 方法的参数是 Predicate 接口：collect该方法接受一个 Collector 类型的函数式接口。可以结合 Collectors 提供的方法来完成操作。将所有来自上海的用户存入一个列表中：List&amp;lt;User&amp;gt; usersFromShanghai = allUsers.stream() .filter(user -&amp;gt; user.isFrom(&quot;Shanghai&quot;)) .collect(Collectors.toList());统计每个地区用户的数量，这个操作与 SQL 中的 group by 类似。：Map&amp;lt;String, Long&amp;gt; userMap = allUsers.stream() // 以 User 的 location 进行分组，对每个分组计数 .collect(Collectors.groupingBy(User::getLocation, Collectors.counting()));collect() 方法还可以完成很多操作，以上只是其中一种。mapmap() 可以将一个流中的值转换为一个新的流。将一个字符串列表全部转为大写：List&amp;lt;String&amp;gt; list = Stream.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) // 将每个字符串转换成大写 .map(str -&amp;gt; str.toUpperCase()) // 转换为列表 .collect(Collectors.toList());这里传给 map() 的 lambda 表达式接受一个 String 类型的参数，返回一个新的 String。参数和返回值可以不属于同一种类型。map() 方法的参数是 Function 函数式接口：flatMapflatMap() 将一个流中每一个值都转换为 Stream 对象。可以使用该方法将多个列表合并：List&amp;lt;Integer&amp;gt; together = Stream.of(Arrays.asList(1, 2, 3), Arrays.asList(4, 5, 6)) // 将每个列表都转换成 Stream .flatMap(numbers -&amp;gt; numbers.stream()) // 转换成列表 .collect(Collectors.toList());flatMap() 方法的参数也是 Function 接口，唯一的区别在于返回值限定为 Stream 类型。reducereduce() 方法可以实现从一组值中生成一个值。对一个列表进行求和：int sum = Stream.of(1, 2, 3, 4) .reduce(0, (acc, e) -&amp;gt; acc + e);对一个列表求阶乘：int sum = together.stream() .reduce(1, (acc, e) -&amp;gt; acc * e);" }, { "title": "Java ThreadLocal 的使用与源码解析", "url": "/blog/posts/Java-ThreadLocal-%E7%9A%84%E4%BD%BF%E7%94%A8%E4%B8%8E%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/", "categories": "Java, 线程", "tags": "Java, 线程", "date": "2019-10-22 22:00:00 +0800", "snippet": "ThreadLocal 主要解决的是每个线程绑定自己的值，可以将 ThreadLocal 看成全局存放数据的盒子，盒子中存储每个线程的私有数据。验证线程变量的隔离性import static java.lang.System.out;public class Run { private static ThreadLocal&amp;lt;Integer&amp;gt; threadLocal = new ThreadLocal&amp;lt;&amp;gt;(); static class Work extends Thread { @Override public void run() { threadLocal.set(0); for (int i = 1; i &amp;lt;= 5; i++) { // 获取数据 int sum = threadLocal.get(); out.printf(&quot;%s&#39;s sum = %s\\n&quot;, getName(), threadLocal.get()); sum += i; // 写回数据 threadLocal.set(sum); } out.printf(&quot;END %s&#39;s sum = %d\\n\\n&quot;, getName(), threadLocal.get()); } } public static void main(String[] args) { Work work1 = new Work(), work2 = new Work(); work1.start(); work2.start(); }}运行结果：Thread-0&#39;s sum = nullThread-1&#39;s sum = nullThread-1&#39;s sum = 1Thread-1&#39;s sum = 3Thread-1&#39;s sum = 6Thread-1&#39;s sum = 10END Thread-1&#39;s sum = 15Thread-0&#39;s sum = 1Thread-0&#39;s sum = 3Thread-0&#39;s sum = 6Thread-0&#39;s sum = 10END Thread-0&#39;s sum = 15Process finished with exit code 0从结果来看，两个线程的计算结果一致，ThreadLocal 中隔离了两个线程的数据。ThreadLocal 源码解析ThreadLocalMap 内部类在 ThreadLocal 中有一个 ThreadLocalMap 内部类，所以 ThreadLocal 实际上是使用一个哈希表来存储每个线程的数据的。ThreadLocalMap 与 HashMap 不同，其中 Entry 是一个弱引用，这意味着每次垃圾回收运行时都会将储存的数据回收掉。而且它只使用了数组来存储键值对。ThreadLocalMap 中的 Entry ：static class Entry extends WeakReference&amp;lt;ThreadLocal&amp;lt;?&amp;gt;&amp;gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&amp;lt;?&amp;gt; k, Object v) { super(k); value = v; } }get() 方法public T get() { // 得到当前线程 Thread t = Thread.currentThread(); // 获取当前线程的哈希表 ThreadLocalMap map = getMap(t); if (map != null) { // 从哈希表中获取当前线程的数据 ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) { @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; } } return setInitialValue();}get() 方法首先得到当前线程，然后获取当前线程的 ThreadLocalMap 对象，然后从中取出数据。这里的 map.getEntry(this) 看起来很奇怪，在前面有这样一行代码：ThreadLocalMap map = getMap(t);这个方法获取当前线程的 ThreadLocalMap 对象，所以，虽然 map.getEntry() 中的 key 总是 ThreadLocal 对象本身，但是每个线程都持有有自己的 ThreadLocalMap 对象。getMap() 方法/** * Get the map associated with a ThreadLocal. Overridden in * InheritableThreadLocal. * * @param t the current thread * @return the map */ThreadLocalMap getMap(Thread t) { return t.threadLocals;}看到这个方法，get() 方法中 map.getEntry(this) 的迷雾就解开了。这里可以看到返回的是线程中的 threadLocals 属性。那么这里瞟一眼 Thread 的源码：/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null;其实每次 get() 时都是先获取了线程自己的 ThreadLocalMap 对象，然后对这个对象进行操作。set() 方法public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else // 为当前线程创建一个 ThreadLocalMap 对象 createMap(t, value);}set() 方法也是先获取当前线程自己的 ThreadLocalMap 对象，然后再设置数据。如果获取的哈希表为 null，则创建一个。createMap() 方法void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue);}createMap() 方法创建一个 ThreadLocalMap 对象，该对象由线程持有。总结 ThreadLocal 可以隔离线程的变量，每个线程只能从这个对象中获取到属于自己的数据。 ThreadLocal 使用哈希表来存储线程的数据，而且这个哈希表是由线程自己持有的，每次获取和设值都会先获取当前线程持有的ThreadLocalMap 对象。 ThreadLocalMap 中的 key 总是 ThreadLocal 对象本身。 ThreadLocalMap 中的 Entry 是弱引用，每次 GC 运行都会被回收。" }, { "title": "Java 线程的基本使用", "url": "/blog/posts/Java-%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/", "categories": "Java, 线程", "tags": "Java, 线程", "date": "2019-10-20 21:00:00 +0800", "snippet": "创建线程创建线程的方式有两种： 继承 Thread 类 实现 Runnable 接口Thread 类实现了 Runnable 接口。使用继承 Thread 类的方式创建线程时，最大的局限是不支持多继承。所以为了支持多继承，应该使用实现 Runnable 接口的方式。两种方式创建的线程在工作时是一样的，没有本质区别。第一种方式，继承 Thread 类并重写 run() 方法：public class Work extends Thread { @Override public void run() { System.out.println(&quot;Working...&quot;); }}public class Run { public static void main(String[] args) { Work work = new Work(); work.start(); System.out.println(&quot;End!&quot;); }}运行结果可能 “End！”先输出。在使用多线程时，运行结果与调用顺序是无关的。 调用 run() 方法只是普通的方法调用，不会启动线程。如果多次调用 start() 方法，会抛出 IllegalThreadStateException 异常。第二种方式，实现 Runnable 接口：public class Work implements Runnable { @Override public void run() { System.out.println(&quot;Working...&quot;); }}public class Run { public static void main(String[] args) { Thread t = new Thread(new Work()); t.start(); System.out.println(&quot;End!&quot;); }}这种方式与第一种在运行上没有什么区别。其优点在于突破了单继承的限制。Thread 类的部分构造方法： 构造方法 说明 Thread() 创建一个新的线程 Thread(String name) 创建一个新的线程，并指定名称 Thread(Runnable target) 创建一个新的线程，将 target 作为运行对象 Thread(Runnable target, String name) 将 target 作为运行对象，并指定名称 Thread(ThreadGroup group, Runnable target) 将 target 作为运行对象，并作为线程组的一员 线程的方法currentThread() 方法currentThread() 方法返回正在被执行的线程的信息。public class Run() { public static void main(String[] args) { System.out.println(Thread.currentThread().getName()); }}以上代码在控制台输出 “main“，说明该方法被名为 main 的线程调用。import static java.lang.System.out;public class Run { static class Work extends Thread { @Override public void run() { out.printf(&quot;%s 被调用\\n&quot;, currentThread().getName()); } } public static void main(String[] args) { Work t1 = new Work(), t2 = new Work(); t1.start(); t2.start(); }}以上代码运行结果：Thread-0 被调用Thread-1 被调用Process finished with exit code 0 在 run() 方法中可以省略 Thread 直接调用 currentThread() 方法。isAlive() 方法该方法判断当前线程是否处于活动状态。import static java.lang.System.out;public class Run { static class Work extends Thread { @Override public void run() { out.printf(&quot;运行中 %s\\n&quot;, isAlive()); } } public static void main(String[] args) throws Throwable { Work t = new Work(); out.printf(&quot;运行前: %s\\n&quot;, t.isAlive()); t.start(); // 等待线程运行完成 Thread.sleep(1000); out.printf(&quot;运行结束: %s\\n&quot;, t.isAlive()); }}以上代码运行结果：运行前: false运行中 true运行结束: falseProcess finished with exit code 0sleep() 方法sleep() 方法指定毫秒数让当前线程休眠（暂停运行），该操作不会释放锁。停止线程interrupt() 方法interrupt() 方法并不能立刻停止线程，只是在在线程中打了一个停止的标记。import static java.lang.System.out;public class StopThread { static class Work extends Thread { @Override public void run() { for (int i = 1; i &amp;lt;= 50000; i++) { out.printf(&quot;i = %d\\n&quot;, i); } } } public static void main(String[] args) throws Throwable { Work work = new Work(); work.start(); Thread.sleep(200); work.interrupt(); out.println(&quot;Call interrupt!&quot;); }}以上代码运行结果：...i = 8190i = 8191i = 8192Call interrupt!i = 8193i = 8194i = 8195...interrupt() 方法调用后，线程仍在运行。要使用 interrupt() 方法停止线程，需要在线程中判断中断状态，有两个方法： interrupted()：测试当前线程是否是中断状态，执行后将状态清除，设置为 false； isInterrupted()：作用同上，但是不清除状态。import static java.lang.System.out;public class StopThread { static class Work extends Thread { @Override public void run() { for (int i = 1; i &amp;lt;= 50000; i++) { if (isInterrupted()) { out.println(&quot;跳出循环!&quot;); break; } out.printf(&quot;i = %d\\n&quot;, i); } } } public static void main(String[] args) throws Throwable { Work work = new Work(); work.start(); Thread.sleep(200); work.interrupt(); out.println(&quot;Call interrupt!&quot;); }}以上代码执行结果：...i = 8301i = 8302i = 8303i = 8304i = 8305i = 8306i = 8307Call interrupt!跳出循环!Process finished with exit code 0在调用 interrupt() 方法后，循环已经退出。但是这种方式只是跳出了循环，假如 for 循环外还有代码，仍然会执行。抛出异常停止线程可以在判断线程状态为中断时，抛出一个异常，在 catch 或 finally 块中做中断后的处理：import static java.lang.System.out;public class StopThread { static class Work extends Thread { @Override public void run() { try { for (int i = 1; i &amp;lt;= 50000; i++) { if (isInterrupted()) { out.println(&quot;Interrupted！&quot;); throw new InterruptedException(&quot;抛出异常！&quot;); } out.printf(&quot;i = %d\\n&quot;, i); } out.println(&quot;for 循环结束!&quot;); } catch (InterruptedException e) { out.println(e.getMessage()); } } } public static void main(String[] args) throws Throwable { Work work = new Work(); work.start(); Thread.sleep(200); work.interrupt(); out.println(&quot;Call interrupt!&quot;); }}以上代码将线程要执行的任务放入 try 块中，当判断为中断状态时，抛出 InterruptedException ，如果需要释放锁，可以在 finally 块中执行。也可以配合 return 来停止线程：if (isInterrupted()) { return;}暂停线程Java 提供了 suspend() 和 resume() 方法来暂停和恢复线程，不过这两个方法已经过期作废了。suspend() 方法暂停线程时，不会释放锁。所以使用 suspend() 方法容易产生死锁。如果需要暂停线程，可以加入一个标记，若标记指出线程需要暂停，使用 wait() 进入等待状态，如需要恢复，使用 notify() 唤醒。import static java.lang.System.out;public class StopThread { static class Work extends Thread { // 暂停标记 private boolean isSuspended = false; void pause() { isSuspended = true; } synchronized void wake() { isSuspended = false; // 唤醒 this.notify(); out.println(&quot;已唤醒!&quot;); } @Override public void run() { synchronized (this) { try { for (int i = 1; i &amp;lt;= 5000; i++) { if (isInterrupted()) { return; } if (isSuspended) { out.println(&quot;已暂停!&quot;); // 等待 this.wait(); } out.printf(&quot;%s i = %d\\n&quot;, getName(), i); } out.printf(&quot;%s end!\\n&quot;, getName()); } catch (InterruptedException e) { out.println(e.getMessage()); } } } } public static void main(String[] args) throws Throwable { Work work = new Work(); work.start(); Thread.sleep(100); // 暂停 work.pause(); Thread.sleep(100); // 唤醒 work.wake(); }}以上代码使用 wait() 和 notify() 暂停与恢复线程。运行结果：...Thread-0 i = 202Thread-0 i = 203Thread-0 i = 204已暂停!已唤醒!Thread-0 i = 205Thread-0 i = 206Thread-0 i = 207...Thread-0 i = 4998Thread-0 i = 4999Thread-0 i = 5000Thread-0 end!Process finished with exit code 0yield 方法yield() 方法的作用是放弃当前的 CPU 资源，让其他的任务去占用 CPU 执行时间。但放弃的时间不确定，有可能刚刚放弃，马上又获得时间片。import static java.lang.System.currentTimeMillis;import static java.lang.System.out;public class Yield { static class Work extends Thread { @Override public void run() { long before = currentTimeMillis(); int sum = 0; for (int i =1; i &amp;lt; 2000000; i++) { // yield(); sum += (i + 1); } long after = currentTimeMillis(); out.printf(&quot;Cost: %dms\\n&quot;, after - before); } } public static void main(String[] args) { new Work().start(); }}以上代码不使用 yield() 方法时大概 15ms 执行完，加上后大概有 500ms。" }, { "title": "Java ArrayList", "url": "/blog/posts/Java-ArrayList/", "categories": "Java, 集合框架", "tags": "Java, 集合框架", "date": "2019-10-09 22:00:00 +0800", "snippet": "ArrayList 继承于 AbstractList ，实现了 List、RandomAccess、Cloneable、Serializable 接口。ArrayList 的底层数据结构是数组，元素超出容量时会进行扩容操作。ArrayList 中的属性private static final int DEFAULT_CAPACITY = 10;private static final Object[] EMPTY_ELEMENTDATA = {};private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};transient Object[] elementData;private int size;private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; DEFAULT_CAPACITY：默认容量为 10。 EMPTY_ELEMENTDATA：通过构造方法指定的容量为 0 时，使用该空数组。 DEFAULTCAPACITY_EMPTY_ELEMENTDATA：调用无参构造方法时，使用该数组。 elementData：保存添加的元素，在 ArrayList 被序列化时，该属性不会被序列化。 size：ArrayList 保存的元素个数。 MAX_ARRAY_SIZE：ArrayList 能够容纳的最大长度，231 - 1 - 8。ArrayList 的构造方法 ArrayList()：构造一个容量为 10 的空列表。 ArrayList(int initialCapacity)：构造一个指定容量的空列表。 ArrayList(Collection&amp;lt;? extends E&amp;gt; c)：构造一个列表，将给定集合中的元素按照迭代器返回的顺序复制到列表中。使用无参构造方法创建 ArrayList 时，elementData 的长度是 0，当第一次添加元素时，它会扩容到 DEFAULT_CAPACITY 。使用指定容量构造 ArrayList 时，elementData 的长度为指定的长度。ArrayList()/** * Constructs an empty list with an initial capacity of ten. * 构造一个容量为 10 的空列表，当第一次添加元素时，elementData 会扩容到 10。 */public ArrayList() { this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;}ArrayList(int initialCapacity)/** * Constructs an empty list with the specified initial capacity. * 构造一个指定容量的空列表 * * @param initialCapacity the initial capacity of the list 列表的初始容量 * @throws IllegalArgumentException if the specified initial capacity * is negative 指定容量 &amp;lt; 0 时抛出异常 */public ArrayList(int initialCapacity) { if (initialCapacity &amp;gt; 0) { this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { this.elementData = EMPTY_ELEMENTDATA; } else { throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); }}ArrayList(Collection&amp;lt;? extends E&amp;gt; c)/** * Constructs a list containing the elements of the specified * collection, in the order they are returned by the collection&#39;s * iterator. * 构造一个列表，并将给定的集合中的元素按照迭代器返回的顺序复制到列表中。 * * @param c the collection whose elements are to be placed into this list 将被复制到列表中的元素的集合 * @throws NullPointerException if the specified collection is null 集合为空时抛出异常 */public ArrayList(Collection&amp;lt;? extends E&amp;gt; c) { elementData = c.toArray(); if ((size = elementData.length) != 0) { // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); } else { // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; }}集合转换为数组后，如果不是 Object[] 类型，会使用 Arrays.copyOf 方法返回一个新的 Object 数组。元素操作的基本方法 方法名 说明 时间复杂度 E get(int index) 返回指定索引的元素 O(1) E set(int index, E element) 替换指定索引的元素，返回旧元素 O(1) boolean add(E e) 向列表的末尾添加元素 O(1) void add(int index, E element) 在指定位置插入元素 O(N) E remove(int index) 删除指定位置的元素，返回旧元素 O(N) boolean remove(Object o) 删除列表中与给定对象相同的元素 O(N) boolean contains(Object o) 判断列表中是否包含指定元素 O(N) int indexOf(Object o) 返回指定元素在列表中的索引 O(N) 其中，contains 方法直接 返回 indexOf(o) &amp;gt;= 0 。对列表操作的方法clear()清空列表，将所有元素的引用指向 null，等待垃圾回收器回收，此操作不减小数组容量。public void clear() { modCount++; // clear to let GC do its work for (int i = 0; i &amp;lt; size; i++) elementData[i] = null; size = 0;}subList(int fromIndex, int toIndex)返回列表的指定区域（子列表），对返回的列表做修改会影响整个列表。public List&amp;lt;E&amp;gt; subList(int fromIndex, int toIndex) { subListRangeCheck(fromIndex, toIndex, size); return new SubList(this, 0, fromIndex, toIndex);}迭代器方法iterator()返回一个迭代器，如果在迭代器遍历过程中调用了列表的 add，remove 等方法，会抛出 ConcurrentModificationException 。public Iterator&amp;lt;E&amp;gt; iterator() { return new Itr();}listIterator()返回一个迭代器，该迭代器可以向前后两个方向遍历元素。ListIter 继承于 Iter 。public ListIterator&amp;lt;E&amp;gt; listIterator() { return new ListItr(0);}listIterator(int index)返回一个从指定位置开始的迭代器。public ListIterator&amp;lt;E&amp;gt; listIterator(int index) { if (index &amp;lt; 0 || index &amp;gt; size) throw new IndexOutOfBoundsException(&quot;Index: &quot;+index); return new ListItr(index);}扩容方法ArrayList 有两个与扩容有关的方法： void grow(int minCapacity) int hugeCapacity(int minCapacity)grow(int minCapacity)private void grow(int minCapacity) { // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &amp;gt;&amp;gt; 1); if (newCapacity - minCapacity &amp;lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &amp;gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);}minCapacity 为添加新元素后数组的长度（此时还未添加）。首先将新长度（newCapacity）设置为原来的 1.5 倍，然后计算新的长度是否能够达到 minCapacity，如果不能，则把新长度设置为 minCapacity 的大小。如果新长度比 ArrayList 能够容纳的最大长度还要大，调用 hugeCapacity 方法来计算。否则，将列表长度调整为新长度。hugeCapacity(int minCapacity)private static int hugeCapacity(int minCapacity) { if (minCapacity &amp;lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &amp;gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;}这里为什么要判断 minCapacity &amp;lt; 0 ？假如列表中已经有 oldCapacity = 231 - 1 个元素，在添加新元素的时候，minCapacity 为原来的长度 + 1，溢出变为 minCapacity = -231，newCapacity 扩大到 1.5 倍也溢出为负数（绝对值 &amp;lt; minCapacity），此时 grow 方法中 newCapacity - minCapacity &amp;gt; 0（绝对值小的负数 - 绝对值大的负数），最后调用该方法时传递的 minCapacity 就是 -231，将抛出异常。最后如果 minCapacity 大于 ArrayList 能容纳的最大长度，就返回整型最大值，否则返回 MAX_ARRAY_SIZE。函数式接口方法ArrayList 有 4 个参数为函数式接口的方法：1. forEach(Consumer&amp;lt;? super E&amp;gt; action)消费列表中的元素，可以对列表中的元素作出处理。以下代码打印列表中所有的偶数：ArrayList&amp;lt;Integer&amp;gt; list = ...;list.forEach(e -&amp;gt; { if (e % 2 == 0) System.out.printf(&quot;%d &quot;, e);});2. removeIf(Predicate&amp;lt;? super E&amp;gt; filter)删除列表中满足给定条件的元素。以下代码删除列表中所有偶数元素：list.removeIf(e -&amp;gt; { return e % 2 == 0;});也可以这样写：list.removeIf(e -&amp;gt; e % 2 == 0);3. replaceAll(UnaryOperator operator)替换列表中满足给定条件的元素。以下代码将所有偶数元素替换为 0 ：list.replaceAll(e -&amp;gt; { return e % 2 == 0 ? 0 : e;});也可以这样写：list.replaceAll(e -&amp;gt; e % 2 == 0 ? 0 : e);4. sort(Comparator&amp;lt;? super E&amp;gt; c)使用给定的规则对列表元素排序。如果元素的类型已经实现了 Comparable 接口，可以直接传递方法引用。以下代码对列表进行升序排序：list.sort(Integer::compareTo);逆序可以使用 Comparator.reverseOrder ：list.sort(Comparator.reverseOrder());也可以在 lambda 表达式中写判断逻辑。" }, { "title": "JVM 内存模型", "url": "/blog/posts/JVM-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/", "categories": "JVM", "tags": "JVM", "date": "2019-10-08 12:00:00 +0800", "snippet": "抽象模型程序计数器（Program Counter Register） 程序计数器是 JVM 中一块较小的内存区域，保持当前线程执行的字节码指令的内存地址。 如果线程执行的是 Java 方法，计数器记录的是正在执行的字节码指令的地址，如果正在执行的是 native 方法，计数器的值为 undefined。 为了使线程切换后能够恢复到正确的执行位置，每个线程都有一个独立的程序计数器，各线程互不影响。虚拟机栈（VM Stack）虚拟机栈是线程隔离的，每个线程都有自己独立的虚拟机栈，这个栈中又会包含多个栈帧。 每调用一个方法时就会往栈中压入一个栈帧。 栈帧存储局部变量表、操作栈、动态链接、方法出口等信息。 每一个方法从调用到返回的过程，就对应一个栈帧从入栈到出栈的过程。 虚拟机栈的内存通过 -Xss 参数分配。本地方法栈（Native Method Stack） 本地方法栈的功能和特点与虚拟机栈类似，具有线程隔离的特点，能抛出 StackOverFlowError 和 OutOfMemory 异常。 本地方法栈服务的是对象是 JVM 执行的 native 方法。 HotSpot 虚拟机不区分虚拟机栈和本地方法栈，两者是一块。方法区（Method Area） 保存被加载过的类的信息，static 变量信息也保存在方法区中。 方法区是线程共享的，当有多个线程都用到一个类的时候，而这个类还没有加载，则应该只有一个线程去加载类，让其他线程等待。堆（Heap）在 JVM 所管理的内存中，堆区是最大的一块。Java 堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可。堆分为新生代和老年代。新生代又分为 Eden、Survivor From、Survivor To 三个区，他们的比例为 8 : 1 : 1 。 Eden 区：新对象的出生地（如果新对象占用内存很大，会直接分配到老年代）。当 Eden 区内存不够时会触发 MinorGC。 Survivor From 区：上一次 MinorGC 的存活对象。 Survivor To 区：保留了一次 MinorGC 中存活的对象。新生代 MinorGC 使用复制算法： 首先将 Eden 和 Survivor From 区中存活的对象复制到 Survivor To 区（如果对象的年龄达到了老年的标准，放置到老年区）； 把这些对象的年龄 +1（如果 Survivor To 空间不够则放置到老年区）； 清空 Eden 和 Survivor From 区中的对象，将 Survivor To 和 Survivor From 互换，原来的 Survivor To 成为了下一次 MinorGC 时的 Survivor From 区。老年代的对象比较稳定，MajorGC 不会频繁执行。MajorGC 使用标记-整理算法： 扫描老年代对象，标记被回收对象。 将存活对象都向一端移动，然后清理掉端边界外的内存。 可以通过参数 -Xmx -Xms 来指定运行时堆内存大小。" }, { "title": "数据结构--堆", "url": "/blog/posts/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%A0%86/", "categories": "数据结构", "tags": "数据结构", "date": "2019-10-01 00:20:00 +0800", "snippet": "堆（Heap）是一棵完全二叉树，没有使用父指针和子指针，使用数组描述。 完全二叉树的特点：按照从上到下，从左向右的顺序填充，当前层没有填满时不允许填下一层。堆的属性堆分为大根堆（最大堆）和小根堆（最小堆）。 在大根堆中，父节点的值比每一个子节点的值都要大。 在小根堆中，父节点的值比每一个子节点都要小。大根堆的根节点永远是最大值，小根堆的根节点永远是最小值。堆的存储结构将以下数组存放在堆中[7, 6, 5, 2, 3]节点在数组中的位置 i 与它的父子节点之间存在一个映射关系：parent(i) = floor((i - 1) / 2)left(i) = 2i + 1right(i) = 2i + 2一个节点的父节点等于它的索引减去 1 除 2 向下取整。左右节点的索引总是相邻。 节点 索引 父节点索引 左子节点索引 右子节点索引 7 0 -1 1 2 7 1 0 3 4 5 2 0 5 6 2 3 1 7 8 3 4 1 9 10 根节点 7 没有父节点，它的父节点索引是 -1，节点 5、2、3 没有子节点，它们的子节点索引超过了数组的最大索引。在使用时要判断索引是否是有效值。堆的操作两个原子操作保证在插入和删除节点维持堆的属性： shiftUp() ： 如果一个节点比它的父节点大（大根堆）或小（小根堆），需要将这个节点与父节点交换位置。 shiftDown() ：如果一个节点比它的子节点小（大根堆）或大（小根堆），需要将这个节点与（左或者右）子节点交换位置。以上两个操作是一个递归的过程，时间复杂度 O(log N) 。基于这两个原子操作还有一些其他的操作： insert(value) ：在堆的尾部插入一个节点，然后使用 shiftUp() 来修复堆属性。 remove() ：删除并返回堆顶节点。将最后一个节点放被删除节点的位置，然后使用 shiftDown() 来修复堆属性。 removeAt(index) ：删除堆中的任意节点。将被删除节点与最后一个节点交换位置，交换后如果当前节点比父节点大（小），使用 shiftUp() 修复堆属性，如果它比子节点小（大），使用 shiftDown() 修复堆属性。以上所有的操作时间复杂度都是 O(log N) 。堆的可以通过反复调用 insert(value) 来建立。堆的 Java 实现这里使用了泛型和函数式接口，根据指定的 Comparator 来构造堆。package top.cloudli.heap;import java.util.Arrays;import java.util.Comparator;/** * 堆（Heap） * 根据 {@link Comparator} 构造最大（小）堆 * * @author Cloud Li */@SuppressWarnings(&quot;unchecked&quot;)public class Heap&amp;lt;T&amp;gt; { private Object[] heap; private int length = 0; private Comparator&amp;lt;T&amp;gt; cmp= Comparator.comparingInt(Object::hashCode); public Heap(T[] array) { this(array, null); } public Heap(T[] array, Comparator&amp;lt;T&amp;gt; cmp) { heap = new Object[array.length]; if (cmp != null) this.cmp = cmp; build(array); } /** * 构造堆 * * @param array 用来构造堆的元素 */ private void build(T[] array) { for (T e : array) { insert(e); } } /** * 插入一个元素 * * @param e 被插入的元素 */ public void insert(T e) { if (length == heap.length) resize(); heap[length] = e; shiftUp(length); length++; } public T peek() { return (T) heap[0]; } /** * 移除并返回根节点 * * @return 根节点元素 */ public T remove() { T t = (T) heap[0]; heap[0] = heap[length - 1]; length--; shiftDown(0); return t; } /** * 删除指定位置的元素 * * @param i 目标元素索引，起始为 0 * @return 被删除的元素 */ public T removeAt(int i) { if (i &amp;lt; 0 || i &amp;gt;= length) throw new ArrayIndexOutOfBoundsException(i); T t = (T) heap[i]; swap(i, length - 1); length--; if (cmp.compare((T) heap[i], (T) heap[parent(i)]) &amp;gt; 0) { shiftUp(i); } else { shiftDown(i); } return t; } /** * 扩容 */ private void resize() { Object[] old = heap; Object[] t = new Object[old.length &amp;lt;&amp;lt; 1]; System.arraycopy(old, 0, t, 0, old.length); heap = t; } /** * 获取当前元素的父节点索引 * * @param i 当前元素的索引 * @return 父节点索引 floor(i - 1 / 2) */ private int parent(int i) { return (i - 1) &amp;gt;&amp;gt; 1; } /** * 获取当前元素左节点的索引 * * @param i 当前元素的索引 * @return 左节点的索引 2i + 1 */ private int left(int i) { return (i &amp;lt;&amp;lt; 1) + 1; } /** * 获取当前元素右节点的索引 * * @param i 当前元素的索引 * @return 右节点的索引 2i + 2 */ private int right(int i) { return (i &amp;lt;&amp;lt; 1) + 2; } /** * 上移 * * @param i 当前元素的索引 */ private void shiftUp(int i) { int parent = parent(i); if (parent &amp;lt; 0) return; // 如果当前元素比它的父节点大（小），交换位置 if (cmp.compare((T) heap[i], (T) heap[parent]) &amp;gt; 0) { swap(i, parent); shiftUp(parent); } } /** * 下移 * * @param i 当前元素的索引 */ private void shiftDown(int i) { int left = left(i), right = right(i), child; if (left &amp;gt;= length || right &amp;gt;= length) return; // 如果当前元素比它的子节点小（大），交换位置 if (cmp.compare((T) heap[left], (T) heap[i]) &amp;gt; 0) { child = left; } else if (cmp.compare((T) heap[right], (T) heap[i]) &amp;gt; 0) { child = right; } else { child = -1; } if (child != -1) { swap(i, child); shiftDown(child); } } /** * 交换元素 * * @param i 索引 * @param j 索引 */ private void swap(int i, int j) { Object t = heap[i]; heap[i] = heap[j]; heap[j] = t; } public int size() { return length; } public int maxSize() { return heap.length; } @Override public String toString() { Object[] t = new Object[length]; System.arraycopy(heap, 0, t, 0, length); return Arrays.toString(t); }}public class Main { public static void main(String[] args) { Integer[] arr = {5, 2, 7, 3, 6}; // 构造一个大根堆 Heap&amp;lt;Integer&amp;gt; heap = new Heap&amp;lt;&amp;gt;(arr, Integer::compareTo); out.printf(&quot;Size: %d, MaxSize: %d, nodes: %s\\n&quot;, heap.size(), heap.maxSize(), heap.toString()); }}运行结果：Size: 5, MaxSize: 5, nodes: [7, 6, 5, 2, 3]Process finished with exit code 0如果要构造小根堆：Heap&amp;lt;Integer&amp;gt; heap = new Heap&amp;lt;&amp;gt;(arr, Comparator.reverseOrder());如果要使用自定义对象，可以传入一个 lambda 表达式，指定比较规则。" }, { "title": "Java HashMap", "url": "/blog/posts/Java-HashMap/", "categories": "Java, 集合框架", "tags": "Java, 集合框架", "date": "2019-09-26 22:00:00 +0800", "snippet": "HashMap 使用数组、链表和红黑树存储键值对，当链表足够长时，会转换为红黑树。HashMap 是非线程安全的。HashMap 中的常量static final int DEFAULT_INITIAL_CAPACITY = 1 &amp;lt;&amp;lt; 4;static final int MAXIMUM_CAPACITY = 1 &amp;lt;&amp;lt; 30;static final float DEFAULT_LOAD_FACTOR = 0.75f;static final int TREEIFY_THRESHOLD = 8;static final int UNTREEIFY_THRESHOLD = 6;static final int MIN_TREEIFY_CAPACITY = 64; DEFAULT_INITIAL_CAPACITY：初始容量为 16。 MAXIMUM_CAPACITY：最大容量为 230 。 DEFAULT_LOAD_FACTOR：默认装填因子。初始情况下，当键值对数量大于 16 * 装填因子时，就会扩容为原来的 2 倍。 TREEIFY_THRESHOLD：当链表的长度达到该值时，有可能会转化为树。 UNTREEIFY_THRESHOLD：当链表长度小于该值时，会从树退化为链表。 MIN_TREEIFY_CAPACITY：最小树化容量阈值，只有数组的容量大于该值时，才会转化为红黑树，若小于该值，只触发扩容。 HashMap 中的容量用到了移位操作，将一个数 a 左移 n 位相当于：a = a * 2n ，所以 1 « 4 =&amp;gt; 1 * 24 = 16 。因此，HashMap 的容量总是 2 的整数次幂。使用有参构造方法可以指定初始容量和装填因子，指定的容量会被向上调整为 2 的整数次幂（比如给定容量为13，则会调整为 16）。HashMap 中键值对的值可以为 null，可以存在一个 key 为 null 的键值对。结构与容量调整tableSizeFor 方法/** * Returns a power of two size for the given target capacity. */static final int tableSizeFor(int cap) { int n = cap - 1; n |= n &amp;gt;&amp;gt;&amp;gt; 1; n |= n &amp;gt;&amp;gt;&amp;gt; 2; n |= n &amp;gt;&amp;gt;&amp;gt; 4; n |= n &amp;gt;&amp;gt;&amp;gt; 8; n |= n &amp;gt;&amp;gt;&amp;gt; 16; return (n &amp;lt; 0) ? 1 : (n &amp;gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;}该方法在使用构造方法指定容量时调用，返回一个大于 cap 的 2 的整数次幂的最小数。移位运算一共向右移动 31 位。treeifyBin 方法/** * Replaces all linked nodes in bin at index for given hash unless * table is too small, in which case resizes instead. */final void treeifyBin(Node&amp;lt;K,V&amp;gt;[] tab, int hash) { int n, index; Node&amp;lt;K,V&amp;gt; e; // 判断是否达到转化为树的阈值 if (tab == null || (n = tab.length) &amp;lt; MIN_TREEIFY_CAPACITY) resize(); // 没有达到只做扩容操作 else if ((e = tab[index = (n - 1) &amp;amp; hash]) != null) { TreeNode&amp;lt;K,V&amp;gt; hd = null, tl = null; do { TreeNode&amp;lt;K,V&amp;gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else { p.prev = tl; tl.next = p; } tl = p; } while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); }}在调用 put 方法添加键值对时，如果数量达到了 TREEIFY_THRESHOLD ，就会调用 treeifyBin 方法，该方法会再判断一次数组的容量是否达到 MIN_TREEIFY_CAPACITY，如果没有达到，就只做扩容操作，否则将表转化为树。这里的 (n - 1) &amp;amp; hash 就是求余操作，相当于 hash % n，效率更高。只有当 n 为 2 的整数次幂时才可以这样运算，这也是为什么 HashMap 的长度总是 2 的 n 次幂。函数式接口方法replaceAll 方法@Overridepublic void replaceAll(BiFunction&amp;lt;? super K, ? super V, ? extends V&amp;gt; function) { Node&amp;lt;K,V&amp;gt;[] tab; if (function == null) throw new NullPointerException(); if (size &amp;gt; 0 &amp;amp;&amp;amp; (tab = table) != null) { int mc = modCount; for (int i = 0; i &amp;lt; tab.length; ++i) { for (Node&amp;lt;K,V&amp;gt; e = tab[i]; e != null; e = e.next) { e.value = function.apply(e.key, e.value); } } if (modCount != mc) throw new ConcurrentModificationException(); }}该方法接受一个 BiFunction ，将满足给定条件的值替换掉：HashMap&amp;lt;Integer, String&amp;gt; map = ...;// 将 key 为偶数的所有键值对的值替换为 &quot;foo&quot;map.replaceAll((k, v) -&amp;gt; k % 2 == 0 ? &quot;foo&quot; : v);forEach 方法@Overridepublic void forEach(BiConsumer&amp;lt;? super K, ? super V&amp;gt; action) { Node&amp;lt;K,V&amp;gt;[] tab; if (action == null) throw new NullPointerException(); if (size &amp;gt; 0 &amp;amp;&amp;amp; (tab = table) != null) { int mc = modCount; for (int i = 0; i &amp;lt; tab.length; ++i) { for (Node&amp;lt;K,V&amp;gt; e = tab[i]; e != null; e = e.next) action.accept(e.key, e.value); } if (modCount != mc) throw new ConcurrentModificationException(); }}该方法接受一个 BiConsumer ，根据指定的规则消费键值对：// 打印所有键值对map.forEach( (k, v) -&amp;gt; System.out.println(k + &quot;: &quot; + v));// 打印所有 key 为偶数的键值对map.forEach( (k, v) -&amp;gt; { if (k % 2 == 0) System.out.println(k + &quot;: &quot; + v) });" }, { "title": "选择排序", "url": "/blog/posts/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/", "categories": "算法, 排序", "tags": "算法, 排序", "date": "2019-09-26 15:50:00 +0800", "snippet": "原理 将整个序列作为无序区，有序区为空。 从无序区中选出最小（大）的元素，将它与无序区中的第一个元素交换，有序区个数增加 1 个，无序区个数减少 1 个。 重复第 2 步，到第 n - 1 个元素时，排序完成。Java 实现public class SelectionSort { public static void sort(int[] arr, BiPredicate&amp;lt;Integer, Integer&amp;gt; cmp) { for (int i = 0; i &amp;lt; arr.length - 1; i++) { int index = i; for (int j = i + 1; j &amp;lt; arr.length; j++) { // 在未排序的序列中找最小（大）值 if (cmp.test(arr[j], arr[index])) { index = j; } } // 与无序区第一个元素交换 int t = arr[i]; arr[i] = arr[index]; arr[index] = t; } } public static void main(String[] args) { int[] arr = {2, 1, 5, 3, 6, 4, 9, 8, 7, 10}; sort(arr, (a, b) -&amp;gt; a &amp;lt; b); }}算法复杂度 时间复杂度（平均） 时间复杂度（最坏） 时间复杂度（最好） 空间复杂度 稳定性 O(N2) O(N2) O(N2) O(1) 不稳定 " }, { "title": "插入排序", "url": "/blog/posts/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/", "categories": "算法, 排序", "tags": "算法, 排序", "date": "2019-09-25 16:00:00 +0800", "snippet": "原理 首先将第一个元素视为已排序的序列。 取未排序序列中的一个元素，在已排序的序列中从后向前查找，直到找到比当前元素小（大）的位置，然后插入进去。 重复第 2 步，直到整个序列有序。Java 实现public class InsertionSort { public static void sort(int[] arr, BiPredicate&amp;lt;Integer, Integer&amp;gt; cmp) { for (int i = 1; i &amp;lt; arr.length; i++) { if (cmp.test(arr[i], arr[i - 1])) { int t = arr[i]; for (int j = i; j &amp;gt;= 0; j--) { if (j &amp;gt; 0 &amp;amp;&amp;amp; cmp.test(t, arr[j - 1])) { // 将所有比当前元素大（小）的元素向后移动 arr[j] = arr[j - 1]; } else { // 插入 arr[j] = t; break; } } } } } public static void main(String[] args) { int[] arr = {2, 1, 5, 3, 6, 4, 9, 8, 7, 10}; sort(arr, (a, b) -&amp;gt; a &amp;lt; b); }}算法复杂度 时间复杂度（平均） 时间复杂度（最坏） 时间复杂度（最好） 空间复杂度 稳定性 O(N2) O(N2) O(N) O(1) 稳定 " }, { "title": "使用 docker-compose 运行 MySQL", "url": "/blog/posts/%E4%BD%BF%E7%94%A8-docker-compose-%E8%BF%90%E8%A1%8C-MySQL/", "categories": "Docker", "tags": "Docker, MySQL", "date": "2019-09-18 11:45:00 +0800", "snippet": "目录结构.│ .env│ docker-compose.yml│└─mysql ├─config │ my.cnf │ └─datamysql 目录下的 data 为数据目录，mysql 的数据表、二进制日志文件就在这里。.env 文件包含了一些变量，这些变量可以在 docker-compose.yml 文件中通过 ${variable_name} 来引用。 当然也可以把 mysql 的目录放到其它地方，这里图个方便，直接放在 yml 文件同级目录了。.env 文件MYSQL_ROOT_PASSWORD=rootMYSQL_ROOT_HOST=%MYSQL_DIR=./mysqlMySQL 配置文件 my.cnf[mysqld]character-set-server=utf8mb4default-time-zone=&#39;+8:00&#39;innodb_rollback_on_timeout=&#39;ON&#39;max_connections=500innodb_lock_wait_timeout=500如果使用默认配置，这个文件可以省略。docker-compose.ymlversion: &#39;3&#39;services: mysql-db: container_name: mysql-docker # 指定容器的名称 image: mysql:8.0 # 指定镜像和版本 ports: - &quot;3306:3306&quot; environment: MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD} MYSQL_ROOT_HOST: ${MYSQL_ROOT_HOST} volumes: - &quot;${MYSQL_DIR}/data:/var/lib/mysql&quot; # 挂载数据目录 - &quot;${MYSQL_DIR}/config:/etc/mysql/conf.d&quot; # 挂载配置文件目录Environment 变量 MYSQL_ROOT_PASSWORD ：这个不用解释，root 用户的密码。 MYSQL_USER，MYSQL_PASSWORD ：这两个变量为可选，创建一个新用户，这个用户在 MYSQL_DATABASE 变量指定的数据库上拥有超级用户权限。 MYSQL_DATABASE ：指定一个数据库，在容器启动时创建。 MYSQL_ALLOW_EMPTY_PASSWORD ：设置为 yes 允许 root 用户的密码为空。（不推荐） MYSQL_RANDOM_ROOT_PASSWORD ：设置为 yes 将在容器启动时为 root 用户生成一个随机的密码，密码会显示到标准输出流（GENERATED ROOT PASSWORD:......）。 MYSQL_ONETIME_PASSWORD ：字面意思就是一次性密码，为 root 用户设置，第一次登录后必须修改密码（仅支持 5.6 以上的版本）。运行容器在 docker-compose.yml 目录下执行：&amp;gt; docker-compose up如果要在后台运行，使用 docker-compose up -d 。停止容器：&amp;gt; docker-compose down如果是前台运行的，使用：Ctrl + C 停止。这两种方式在停止后都会删除容器，下次启动必须使用 up 命令。停止但不删除容器：&amp;gt; docker-compose stop使用 stop 停止后，再次启动使用 start 命令即可。" }, { "title": "Java lambda表达式", "url": "/blog/posts/Java-lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/", "categories": "Java", "tags": "Java, 函数式编程", "date": "2019-09-16 23:26:00 +0800", "snippet": "lambda 表达式是一个可传递的代码块，可以在以后执行一次或多次。lambda 表达式的语法参数，箭头（-&amp;gt;）以及一个表达式或代码块：(String first, String second) -&amp;gt; { if (first.length() &amp;lt; second.length()) return -1; else if (first.length() &amp;gt; second.length()) return 1; else return 0;}即使没有参数，也要提供空括号：() -&amp;gt; { for (int i = 100; i &amp;gt;= 0; i--) System.out.println(i);}如果可以推导出一个 lambda 表达式的参数类型，则可以忽略其类型：Comparator&amp;lt;String&amp;gt; cmp = (first, second) -&amp;gt; first.length() - second.length();在这里编译器可以推导出 first 和 second 必然是字符串，因为这个 lambda 表达式将赋给一个字符串比较器。如果只有一个参数，且类型可以推导得出，可以省略小括号：ActionListener listener = event -&amp;gt; System.out.println(&quot;The time is &quot; + new Date());无需指定 lamdba 表达式的返回类型。lambda 表达式的返回类型总是会由上下文推导得出。例如下面的表达式可以在需要 int 类型结果的上下文中使用：(String first, String second) -&amp;gt; first.length() - second.length(); 如果一个 lambda 表达式只在某些分支返回一个值，在另外一些分支不返回值是不合法的。函数式接口对于只有一个抽象方法的接口，需要这种接口的对象时，就可以提供一个 lambda 表达式。这种接口称为函数式接口。比如 Arrays.sort 方法，它的第二个参数需要一个 Comparator 实例，Comparator 就是只有一个方法的接口，所以可以传递一个 lambda 表达式：Arrays.sort(words, (first, second) -&amp;gt; first.length() - second.length());在 Java 中，对 lambda 表达式所能做的也只是能转换为函数式接口。在其他支持函数字面量的语言中，可以声明函数类型，可以使用变量保存函数表达式。 不能把 lambda 表达式赋给类型为 Object 的变量，Object 不是一个函数式接口。Java API 在java.util.function 包中定义了很多非常通用的函数式接口。比如 BiFunction&amp;lt;T, U, R&amp;gt; 描述了参数类型为 T 和 U 而返回类型为 R 的函数。可以把字符串比较的 lambda 表达式保存在这个类型的变量中：BiFunction&amp;lt;String, String, Integer&amp;gt; cmp = (first, second) -&amp;gt; first.length() - second.length();java.util.function 包中有一个很有用的接口 Predicate：public interface Predicate&amp;lt;T&amp;gt; { boolean test(T t); ...}ArrayList 类有一个 removeIf 方法，它的参数就是一个 Predicate：list.removeIf(e -&amp;gt; e == null); // 删除所有 null 值常用的函数式接口 函数式接口 参数类型 返回类型 抽象方法名 描述 其他方法 Runnable 无 void run 作为无参数或返回值的动作运行   Supplier&amp;lt;T&amp;gt; 无 T get 提供一个 T 类型的值   Comsumer&amp;lt;T&amp;gt; T void accept 处理一个 T 类型的值 andThen BiComsumer&amp;lt;T, U&amp;gt; T, U void accept 处理 T 和 U 类型的值 andThen Function&amp;lt;T, R&amp;gt; T R apply 有一个 T 类型参数的函数 compose，andThen，identity BiFunction&amp;lt;T, U, R&amp;gt; T, U R apply 有 T 和 U 类型参数的函数 andThen UnaryOperator&amp;lt;T&amp;gt; T T apply 类型 T 上的一元操作符 compose，andThen，identity BinaryOperator&amp;lt;T,&amp;gt; T, T T apply 类型 T 上的二元操作符 andThen，maxBy，minBy Predicate&amp;lt;T&amp;gt; T boolean test 布尔值函数 and，or，negate，isEqual BiPredicate&amp;lt;T, U&amp;gt; T, U boolean test 有两个参数的布尔值函数 and，or，negate 方法引用有时候，可能已经有现成的方法可以完成想要传递到其他代码的某个动作。比如，只要出现一个定时器事件就打印这个事件对象，为此可以调用：Timer t = new Timer(1000, event -&amp;gt; System.out.println(event));这种情况下，可以直接把 println 方法传递到 Timer 构造器：Timer t = new Timer(1000, System.out::println);表达式 System.out::println 是一个方法引用，它等价于 lambda 表达式 x-&amp;gt; System.out.println(x) 。方法引用要用 :: 操作符分隔方法名与对象或类名，主要有 3 种情况： object::instanceMethod Class::staticMethod Class::instanceMethod前 2 种情况，方法引用等价于提供方法参数的 lambda 表达式。System.out::println 等价于 x -&amp;gt; System.out.println(x) 。类似地，Math::pow 等价于 (x, y) -&amp;gt; Math.pow(x, y) 。第 3 种情况，第一个参数会成为方法的目标。例如，String::compareToIgnoreCase 等同于 (x, y) -&amp;gt; x.compareToIgnoreCase(y);可以在方法引用中使用 this 参数。例如，this::equals 等同于 x -&amp;gt; this.equals(x) 。使用 super 也是合法的。构造器引用构造器引用与方法引用类似，只不过方法名为 new 。假设有一个字符串列表，可以把它转化为一个 Person 对象数组：ArrayList&amp;lt;Person&amp;gt; names = ...;Stream&amp;lt;Person&amp;gt; stream = names.stream().map(Person::new);List&amp;lt;Person&amp;gt; people = stream.collect(Collectors.toList());map 方法会为各个元素调用 Person(String) 构造器。可以用数组类型建立构造器引用，例如，int[]::new 是一个构造器引用，它等同于 x -&amp;gt; new int[x] 。 Java 有一个限制，无法构造泛型类型 T 的数组，表达式 new T[n] 会出现错误。Stream 接口有一个 toArray 方法可以返回 Object 数组：Object[] people = stream.toArray() ，如果希望得到一个 Person 数组，可以使用构造器引用：People[] people = stream.toArray(Person::new) 。" }, { "title": "Java 对象克隆", "url": "/blog/posts/Java-%E5%AF%B9%E8%B1%A1%E5%85%8B%E9%9A%86/", "categories": "Java", "tags": "Java", "date": "2019-09-16 11:50:00 +0800", "snippet": "什么是对象克隆如果为一个包含对象引用的变量建立副本，原变量和副本都是同一个对象的引用。任何一个变量的改变都会影响另一个变量。Employee original = new Employee(&quot;Tom&quot;, 50000);Employee copy = original;copy.riseSalary(10); // 会影响 original如果希望 copy 是一个新对象，它的初始状态与 original 相同，但是之后他们各自有自己的状态，这种情况下就可以使用 clone 方法。Employee copy = original.clone();copy.riseSalary(10); // 不改变 original浅克隆与深克隆如果对象只包含基本类型，那么浅克隆没有问题；如果对象包含子对象的引用，克隆域就会得到相同子对象的另一个引用，这样一来，原对象和克隆对象仍然会共享一些信息。如果原对象和浅克隆对象共享的子对象是不可变的，那么这种克隆是安全的。但是通常子对象都是可变的，必须重新定义 clone 方法来建立一个深克隆，同时克隆所有子对象。对于每一个类，需要确定： 默认的 clone 方法是否满足需求； 是否可以在可变的子对象上调用 clone 来修补默认的 clone 方法； 是否不该使用 clone。对于第 1 项或 第 2 项，类必须： 实现 Cloneable 接口； 重新定义 clone 方法，并指定 public 访问修饰符。 Object 类中的 clone 方法声明为 protected，所以不能直接调用 anObject.clone() 。子类只能调用受保护的 clone 方法来克隆它自己的对象。必须重新定义 clone 为 public 才能允许所有方法克隆对象。这里 Cloneable 接口只是作为一个标记，如果一个对象请求克隆，但没有实现这个接口，就会抛出一个受检查异常。即使 clone 默认的浅拷贝能够满足要求，还是需要实现 Cloneable 接口，将 clone 定义为 public，再调用 super.clone() 。class Employee implements Cloneable { public Employee clone() throws CloneNotSupportedException { return (Employee) super.clone(); } ...}建立深克隆：class Employee implements Cloneable { ... public Employee clone() throws CloneNotSupportedException { // 克隆自己 Employee cloned = (Employee) super.clone(); // 克隆可变的域 cloned.hireDay = (Date) hireDay.clone(); return cloned; } ...}实际上，克隆并不常用，标准库只有不到 5% 的类实现了 clone 。" }, { "title": "Spring Boot &amp; MyBatis 实现乐观锁和悲观锁", "url": "/blog/posts/Spring-Boot-&-MyBatis-%E5%AE%9E%E7%8E%B0%E4%B9%90%E8%A7%82%E9%94%81%E5%92%8C%E6%82%B2%E8%A7%82%E9%94%81/", "categories": "Spring Boot, 锁", "tags": "Spring Boot", "date": "2019-09-04 20:25:00 +0800", "snippet": "以转账操作为例，实现并测试乐观锁和悲观锁。全部代码：https://github.com/imcloudfloating/Lock_Demo死锁问题当 A, B 两个账户同时向对方转账时，会出现如下情况： 时刻 事务 1 (A 向 B 转账) 事务 2 (B 向 A 转账) T1 Lock A Lock B T2 Lock B (由于事务 2 已经 Lock A，等待) Lock A (由于事务 1 已经 Lock B，等待) 由于两个事务都在等待对方释放锁，于是死锁产生了，解决方案：按照主键的大小来加锁，总是先锁主键较小或较大的那行数据。建立数据表并插入数据（MySQL）create table account( id int auto_increment primary key, deposit decimal(10, 2) default 0.00 not null, version int default 0 not null);INSERT INTO vault.account (id, deposit, version) VALUES (1, 1000, 0);INSERT INTO vault.account (id, deposit, version) VALUES (2, 1000, 0);INSERT INTO vault.account (id, deposit, version) VALUES (3, 1000, 0);INSERT INTO vault.account (id, deposit, version) VALUES (4, 1000, 0);INSERT INTO vault.account (id, deposit, version) VALUES (5, 1000, 0);INSERT INTO vault.account (id, deposit, version) VALUES (6, 1000, 0);INSERT INTO vault.account (id, deposit, version) VALUES (7, 1000, 0);INSERT INTO vault.account (id, deposit, version) VALUES (8, 1000, 0);INSERT INTO vault.account (id, deposit, version) VALUES (9, 1000, 0);INSERT INTO vault.account (id, deposit, version) VALUES (10, 1000, 0);Mapper 文件悲观锁使用 select … for update，乐观锁使用 version 字段。&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&amp;gt;&amp;lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot; &amp;gt;&amp;lt;mapper namespace=&quot;com.cloud.demo.mapper.AccountMapper&quot;&amp;gt; &amp;lt;select id=&quot;selectById&quot; resultType=&quot;com.cloud.demo.model.Account&quot;&amp;gt; select * from account where id = #{id} &amp;lt;/select&amp;gt; &amp;lt;update id=&quot;updateDeposit&quot; keyProperty=&quot;id&quot; parameterType=&quot;com.cloud.demo.model.Account&quot;&amp;gt; update account set deposit=#{deposit}, version = version + 1 where id = #{id} and version = #{version} &amp;lt;/update&amp;gt; &amp;lt;select id=&quot;selectByIdForUpdate&quot; resultType=&quot;com.cloud.demo.model.Account&quot;&amp;gt; select * from account where id = #{id} for update &amp;lt;/select&amp;gt; &amp;lt;update id=&quot;updateDepositPessimistic&quot; keyProperty=&quot;id&quot; parameterType=&quot;com.cloud.demo.model.Account&quot;&amp;gt; update account set deposit=#{deposit} where id = #{id} &amp;lt;/update&amp;gt; &amp;lt;select id=&quot;getTotalDeposit&quot; resultType=&quot;java.math.BigDecimal&quot;&amp;gt; select sum(deposit) from account; &amp;lt;/select&amp;gt;&amp;lt;/mapper&amp;gt;Mapper 接口@Componentpublic interface AccountMapper { Account selectById(int id); Account selectByIdForUpdate(int id); int updateDepositWithVersion(Account account); void updateDeposit(Account account); BigDecimal getTotalDeposit();}Account POJO@Datapublic class Account { private int id; private BigDecimal deposit; private int version;}AccountService在 transferOptimistic 方法上有个自定义注解 @Retry，这个用来实现乐观锁失败后重试。@Slf4j@Servicepublic class AccountService { public enum Result{ SUCCESS, DEPOSIT_NOT_ENOUGH, FAILED, } @Resource private AccountMapper accountMapper; private BiPredicate&amp;lt;BigDecimal, BigDecimal&amp;gt; isDepositEnough = (deposit, value) -&amp;gt; deposit.compareTo(value) &amp;gt; 0; /** * 转账操作，悲观锁 * * @param fromId 扣款账户 * @param toId 收款账户 * @param value 金额 */ @Transactional(isolation = Isolation.READ_COMMITTED) public Result transferPessimistic(int fromId, int toId, BigDecimal value) { Account from, to; try { // 先锁 id 较大的那行，避免死锁 if (fromId &amp;gt; toId) { from = accountMapper.selectByIdForUpdate(fromId); to = accountMapper.selectByIdForUpdate(toId); } else { to = accountMapper.selectByIdForUpdate(toId); from = accountMapper.selectByIdForUpdate(fromId); } } catch (Exception e) { log.error(e.getMessage()); TransactionAspectSupport.currentTransactionStatus().setRollbackOnly(); return Result.FAILED; } if (!isDepositEnough.test(from.getDeposit(), value)) { TransactionAspectSupport.currentTransactionStatus().setRollbackOnly(); log.info(String.format(&quot;Account %d is not enough.&quot;, fromId)); return Result.DEPOSIT_NOT_ENOUGH; } from.setDeposit(from.getDeposit().subtract(value)); to.setDeposit(to.getDeposit().add(value)); accountMapper.updateDeposit(from); accountMapper.updateDeposit(to); return Result.SUCCESS; } /** * 转账操作，乐观锁 * @param fromId 扣款账户 * @param toId 收款账户 * @param value 金额 */ @Retry @Transactional(isolation = Isolation.REPEATABLE_READ) public Result transferOptimistic(int fromId, int toId, BigDecimal value) { Account from = accountMapper.selectById(fromId), to = accountMapper.selectById(toId); if (!isDepositEnough.test(from.getDeposit(), value)) { TransactionAspectSupport.currentTransactionStatus().setRollbackOnly(); return Result.DEPOSIT_NOT_ENOUGH; } from.setDeposit(from.getDeposit().subtract(value)); to.setDeposit(to.getDeposit().add(value)); int r1, r2; // 先锁 id 较大的那行，避免死锁 if (from.getId() &amp;gt; to.getId()) { r1 = accountMapper.updateDepositWithVersion(from); r2 = accountMapper.updateDepositWithVersion(to); } else { r2 = accountMapper.updateDepositWithVersion(to); r1 = accountMapper.updateDepositWithVersion(from); } if (r1 &amp;lt; 1 || r2 &amp;lt; 1) { // 失败，抛出重试异常，执行重试 throw new RetryException(&quot;Transfer failed, retry.&quot;); } else { return Result.SUCCESS; } }}使用Spring AOP 实现乐观锁失败后重试自定义注解 Retry@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)public @interface Retry { int value() default 3; // 重试次数}重试异常 RetryExceptionpublic class RetryException extends RuntimeException { public RetryException(String message) { super(message); }}重试的切面类tryAgain 方法使用了 @Around 注解（表示环绕通知），可以决定目标方法在何时执行，或者不执行，以及自定义返回结果。这里首先通过 ProceedingJoinPoint.proceed() 方法执行目标方法，如果抛出了重试异常，那么重新执行直到满三次，三次都不成功则回滚并返回 FAILED。@Slf4j@Aspect@Componentpublic class RetryAspect { @Pointcut(&quot;@annotation(com.cloud.demo.annotation.Retry)&quot;) public void retryPointcut() { } @Around(&quot;retryPointcut() &amp;amp;&amp;amp; @annotation(retry)&quot;) @Transactional(isolation = Isolation.READ_COMMITTED) public Object tryAgain(ProceedingJoinPoint joinPoint, Retry retry) throws Throwable { int count = 0; do { count++; try { return joinPoint.proceed(); } catch (RetryException e) { if (count &amp;gt; retry.value()) { log.error(&quot;Retry failed!&quot;); TransactionAspectSupport.currentTransactionStatus().setRollbackOnly(); return AccountService.Result.FAILED; } } } while (true); }}单元测试用多个线程模拟并发转账，经过测试，悲观锁除了账户余额不足，或者数据库连接不够以及等待超时，全部成功；乐观锁即使加了重试，成功的线程也很少，500 个平均也就十几个成功。所以对于写多读少的操作，使用悲观锁，对于读多写少的操作，可以使用乐观锁。 完整代码请见 Github：https://github.com/imcloudfloating/Lock_Demo。@Slf4j@SpringBootTest@RunWith(SpringRunner.class)class AccountServiceTest { // 并发数 private static final int COUNT = 500; @Resource AccountMapper accountMapper; @Resource AccountService accountService; private CountDownLatch latch = new CountDownLatch(COUNT); private List&amp;lt;Thread&amp;gt; transferThreads = new ArrayList&amp;lt;&amp;gt;(); private List&amp;lt;Pair&amp;lt;Integer, Integer&amp;gt;&amp;gt; transferAccounts = new ArrayList&amp;lt;&amp;gt;(); @BeforeEach void setUp() { Random random = new Random(currentTimeMillis()); transferThreads.clear(); transferAccounts.clear(); for (int i = 0; i &amp;lt; COUNT; i++) { int from = random.nextInt(10) + 1; int to; do{ to = random.nextInt(10) + 1; } while (from == to); transferAccounts.add(new Pair&amp;lt;&amp;gt;(from, to)); } } /** * 测试悲观锁 */ @Test void transferByPessimisticLock() throws Throwable { for (int i = 0; i &amp;lt; COUNT; i++) { transferThreads.add(new Transfer(i, true)); } for (Thread t : transferThreads) { t.start(); } latch.await(); Assertions.assertEquals(accountMapper.getTotalDeposit(), BigDecimal.valueOf(10000).setScale(2, RoundingMode.HALF_UP)); } /** * 测试乐观锁 */ @Test void transferByOptimisticLock() throws Throwable { for (int i = 0; i &amp;lt; COUNT; i++) { transferThreads.add(new Transfer(i, false)); } for (Thread t : transferThreads) { t.start(); } latch.await(); Assertions.assertEquals(accountMapper.getTotalDeposit(), BigDecimal.valueOf(10000).setScale(2, RoundingMode.HALF_UP)); } /** * 转账线程 */ class Transfer extends Thread { int index; boolean isPessimistic; Transfer(int i, boolean b) { index = i; isPessimistic = b; } @Override public void run() { BigDecimal value = BigDecimal.valueOf( new Random(currentTimeMillis()).nextFloat() * 100 ).setScale(2, RoundingMode.HALF_UP); AccountService.Result result = AccountService.Result.FAILED; int fromId = transferAccounts.get(index).getKey(), toId = transferAccounts.get(index).getValue(); try { if (isPessimistic) { result = accountService.transferPessimistic(fromId, toId, value); } else { result = accountService.transferOptimistic(fromId, toId, value); } } catch (Exception e) { log.error(e.getMessage()); } finally { if (result == AccountService.Result.SUCCESS) { log.info(String.format(&quot;Transfer %f from %d to %d success&quot;, value, fromId, toId)); } latch.countDown(); } } }}MySQL 配置innodb_rollback_on_timeout=&#39;ON&#39;max_connections=1000innodb_lock_wait_timeout=500" } ]
